ray:
  dashboard: 0.0.0.0:8265
  num_cpus: 4

actor_rollout_ref:
  max_token: 2048
  model:
    name: Llama-3.1-8B-Instruct
    path: meta-llama/Llama-3.1-8B-Instruct
    strategy: FSDP

algorithm:
  aggregation_loss: GAE
  gamma: 1.0
  kl:
    adaptive: false
    coef: 0.001
    horizon: 10000
    penalty: KL
    target: 0.1
    use_in_reward: false
  lam: 1.0
  norm_adv_by_std_in_grpo: false
  reward_manager: NAIVE

trainer:
  balance_batch: true
  experiment_name: default
  n_gpus_per_node: 1
  n_nodes: 1
  project_name: multimeditron_verl
  save_freq: -1
  total_epoch: 1
  total_training_steps: null
  use_console_logging: true
  use_wandb_logging: false

